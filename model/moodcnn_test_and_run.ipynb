{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2635e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from cnn_layers import ConvolutionalLayer, ReLULayer, MaxPoolingLayer, DenseLayer \n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d44271",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# Full folder evaluation\u001b[39;00m\n\u001b[32m     77\u001b[39m     test_dir = \u001b[33m\"\u001b[39m\u001b[33mC:/Users/HP/OneDrive/Desktop/projectWorks/6MoodImage/moodcnnProgram/model/test\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# e.g. dataset/test/happy/, dataset/test/neutral/, dataset/test/sad/\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dir\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(test_folder)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_file \u001b[38;5;129;01min\u001b[39;00m os.listdir(folder_path):\n\u001b[32m     64\u001b[39m     img_path = os.path.join(folder_path, img_file)\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     pred = \u001b[43mpredict_single_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m     total += \u001b[32m1\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m pred.lower() == label.lower():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mpredict_single_image\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Runs full forward pass for one image.\"\"\"\u001b[39;00m\n\u001b[32m     39\u001b[39m img_data = preprocess_image(image_path)\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m out = \u001b[43mconv1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m out = relu1.forward(out)\n\u001b[32m     43\u001b[39m out = pool1.forward(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\HP\\OneDrive\\Desktop\\projectWorks\\6MoodImage\\moodcnnProgram\\model\\cnn_layers.py:54\u001b[39m, in \u001b[36mConvolutionalLayer.forward\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m     51\u001b[39m                 horiz_end = horiz_start + \u001b[38;5;28mself\u001b[39m.filter_size\n\u001b[32m     53\u001b[39m                 current_patch = \u001b[38;5;28mself\u001b[39m.input_padded[n, :, vert_start:vert_end, horiz_start:horiz_end]\n\u001b[32m---> \u001b[39m\u001b[32m54\u001b[39m                 conv_output[n, filter_index, i, j] = np.sum(current_patch * \u001b[38;5;28mself\u001b[39m.filters[filter_index]) + \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m.biases[filter_index])\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m conv_output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# ---- Import your layer classes ----\n",
    "# (Make sure these are defined somewhere accessible)\n",
    "# from your_model_file import ConvolutionalLayer, MaxPoolingLayer, DenseLayer, ReLULayer\n",
    "\n",
    "# ---- 1️⃣ Rebuild model ----\n",
    "conv1 = ConvolutionalLayer(input_shape=(1, 48, 48), filter_size=3, number_of_filters=8, stride=1, padding=1)\n",
    "pool1 = MaxPoolingLayer(pool_size=2, stride=2)\n",
    "conv2 = ConvolutionalLayer(input_shape=(conv1.number_of_filters, 24, 24), filter_size=3, number_of_filters=16, stride=1, padding=1)\n",
    "pool2 = MaxPoolingLayer(pool_size=2, stride=2)\n",
    "relu1 = ReLULayer()\n",
    "relu2 = ReLULayer()\n",
    "\n",
    "flattened_size = conv2.number_of_filters * 12 * 12\n",
    "dense = DenseLayer(input_size=flattened_size, output_size=3)  # 3 moods: happy, neutral, sad\n",
    "\n",
    "# ---- 2️⃣ Load weights ----\n",
    "conv1.filters = np.load(\"conv1_filters.npy\")\n",
    "conv1.biases = np.load(\"conv1_biases.npy\")\n",
    "conv2.filters = np.load(\"conv2_filters.npy\")\n",
    "conv2.biases = np.load(\"conv2_biases.npy\")\n",
    "dense.weights = np.load(\"dense_weights.npy\")\n",
    "dense.biases = np.load(\"dense_biases.npy\")\n",
    "\n",
    "# ---- 3️⃣ Define class map ----\n",
    "class_map = {0: \"happy\", 1: \"neutral\", 2: \"sad\"}\n",
    "\n",
    "\n",
    "# ---- 4️⃣ Define helper functions ----\n",
    "def preprocess_image(image_path):\n",
    "    img = Image.open(image_path).convert(\"L\").resize((48, 48))\n",
    "    img_data = np.array(img) / 255.0\n",
    "    return img_data.reshape(1, 1, 48, 48)  # (batch, channel, height, width)\n",
    "\n",
    "\n",
    "def predict_single_image(image_path):\n",
    "    \"\"\"Runs full forward pass for one image.\"\"\"\n",
    "    img_data = preprocess_image(image_path)\n",
    "\n",
    "    out = conv1.forward(img_data)\n",
    "    out = relu1.forward(out)\n",
    "    out = pool1.forward(out)\n",
    "\n",
    "    out = conv2.forward(out)\n",
    "    out = relu2.forward(out)\n",
    "    out = pool2.forward(out)\n",
    "\n",
    "    flat = out.reshape(out.shape[0], -1)\n",
    "    pred = dense.forward(flat)\n",
    "    predicted_class = np.argmax(pred)\n",
    "    return class_map[predicted_class]\n",
    "\n",
    "\n",
    "def evaluate_model(test_folder):\n",
    "    \"\"\"Evaluates all test images inside subfolders like test/happy/, test/neutral/, test/sad/\"\"\"\n",
    "    total, correct = 0, 0\n",
    "    for label in os.listdir(test_folder):\n",
    "        folder_path = os.path.join(test_folder, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "\n",
    "        for img_file in os.listdir(folder_path):\n",
    "            img_path = os.path.join(folder_path, img_file)\n",
    "            pred = predict_single_image(img_path)\n",
    "            total += 1\n",
    "            if pred.lower() == label.lower():\n",
    "                correct += 1\n",
    "\n",
    "    accuracy = (correct / total) * 100\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}% ({correct}/{total})\")\n",
    "\n",
    "\n",
    "# ---- 5️⃣ Run Tests ----\n",
    "if __name__ == \"__main__\":\n",
    "    # Full folder evaluation\n",
    "    test_dir = \"C:/Users/HP/OneDrive/Desktop/projectWorks/6MoodImage/moodcnnProgram/model/test\"  # e.g. dataset/test/happy/, dataset/test/neutral/, dataset/test/sad/\n",
    "    evaluate_model(test_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abddf2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted mood: 2\n",
      "Predicted mood: sad\n"
     ]
    }
   ],
   "source": [
    "conv1 = ConvolutionalLayer(input_shape=(1,48,48), filter_size=3, number_of_filters=8, stride=1, padding=1)\n",
    "conv2 = ConvolutionalLayer(input_shape=(conv1.number_of_filters, 24, 24), filter_size=3, number_of_filters=16, stride=1, padding=1)\n",
    "pool1 = MaxPoolingLayer(pool_size=2, stride=2)\n",
    "pool2 = MaxPoolingLayer(pool_size=2, stride=2)\n",
    "flattened_size = conv2.number_of_filters * 12 * 12\n",
    "dense = DenseLayer(input_size=flattened_size, output_size=3)  # 3 moods\n",
    "relu1 = ReLULayer()\n",
    "relu2 = ReLULayer()\n",
    "\n",
    "\n",
    "# 2. Load saved weights\n",
    "conv1.filters = np.load(\"conv1_filters.npy\")\n",
    "conv1.biases = np.load(\"conv1_biases.npy\")\n",
    "conv2.filters = np.load(\"conv2_filters.npy\")\n",
    "conv2.biases = np.load(\"conv2_biases.npy\")\n",
    "dense.weights = np.load(\"dense_weights.npy\")\n",
    "dense.biases = np.load(\"dense_biases.npy\")\n",
    "\n",
    "# 3. Load image\n",
    "img = Image.open(\"C:/Users/HP/OneDrive/Desktop/projectWorks/6MoodImage/moodcnnProgram/model/upload_photos/emma.jpg\").convert(\"L\").resize((48,48))\n",
    "img_data = np.array(img)/255.0\n",
    "img_data = img_data.reshape(1,1,48,48)  # batch, channel, height, width\n",
    "\n",
    "# 4. Forward pass\n",
    "out = conv1.forward(img_data)\n",
    "out = relu1.forward(out)\n",
    "out = pool1.forward(out)\n",
    "\n",
    "out = conv2.forward(out)\n",
    "out = relu2.forward(out)\n",
    "out = pool2.forward(out)\n",
    "\n",
    "flat = out.reshape(out.shape[0], -1)\n",
    "pred = dense.forward(flat)\n",
    "\n",
    "predicted_class = np.argmax(pred)\n",
    "print(\"Predicted mood:\", predicted_class)\n",
    "\n",
    "\n",
    "class_map = {0: \"happy\", 1: \"neutral\", 2: \"sad\"}\n",
    "predicted_label = class_map[predicted_class]\n",
    "print(\"Predicted mood:\", predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moodcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
